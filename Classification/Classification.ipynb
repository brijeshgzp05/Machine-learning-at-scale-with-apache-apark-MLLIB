{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification using Logistic Regression on Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv file\n",
    "raw_data = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\", \"true\").load(\"diabetes2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pregnancies',\n",
       " 'Glucose',\n",
       " 'BloodPressure',\n",
       " 'SkinThickness',\n",
       " 'Insulin',\n",
       " 'BMI',\n",
       " 'DiabetesPedigreeFunction',\n",
       " 'Age',\n",
       " 'Outcome']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|Summary|     SkinThickness|           Insulin|\n",
      "+-------+------------------+------------------+\n",
      "|  count|               768|               768|\n",
      "|   mean|20.536458333333332| 79.79947916666667|\n",
      "| stddev|15.952217567727642|115.24400235133803|\n",
      "|    min|                 0|                 0|\n",
      "|    max|                99|               846|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.describe().select(\"Summary\",\"SkinThickness\",\"Insulin\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------------+------------------+\n",
      "|Summary|               BMI|DiabetesPedigreeFunction|               Age|\n",
      "+-------+------------------+------------------------+------------------+\n",
      "|  count|               768|                     768|               768|\n",
      "|   mean|31.992578124999977|      0.4718763020833327|33.240885416666664|\n",
      "| stddev| 7.884160320375441|       0.331328595012775|11.760231540678689|\n",
      "|    min|               0.0|                   0.078|                21|\n",
      "|    max|              67.1|                    2.42|                81|\n",
      "+-------+------------------+------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.describe().select(\"Summary\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+\n",
      "|Summary|       Pregnancies|          Glucose|     BloodPressure|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "|  count|               768|              768|               768|\n",
      "|   mean|3.8450520833333335|     120.89453125|       69.10546875|\n",
      "| stddev|  3.36957806269887|31.97261819513622|19.355807170644777|\n",
      "|    min|                 0|                0|                 0|\n",
      "|    max|                17|              199|               122|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.describe().select(\"Summary\",\"Pregnancies\",\"Glucose\",\"BloodPressure\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------+-------------+----+\n",
      "|Insulin|Glucose|BloodPressure|SkinThickness| BMI|\n",
      "+-------+-------+-------------+-------------+----+\n",
      "|    NaN|  148.0|         72.0|         35.0|33.6|\n",
      "|    NaN|   85.0|         66.0|         29.0|26.6|\n",
      "|    NaN|  183.0|         64.0|          NaN|23.3|\n",
      "|   94.0|   89.0|         66.0|         23.0|28.1|\n",
      "|  168.0|  137.0|         40.0|         35.0|43.1|\n",
      "+-------+-------+-------------+-------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# updating values 0 with np.nan\n",
    "raw_data=raw_data.withColumn(\"Glucose\",F.when(raw_data.Glucose==0,np.nan).otherwise(raw_data.Glucose))\n",
    "raw_data=raw_data.withColumn(\"BloodPressure\",F.when(raw_data.BloodPressure==0,np.nan).otherwise(raw_data.BloodPressure))\n",
    "raw_data=raw_data.withColumn(\"SkinThickness\",F.when(raw_data.SkinThickness==0,np.nan).otherwise(raw_data.SkinThickness))\n",
    "raw_data=raw_data.withColumn(\"BMI\",F.when(raw_data.BMI==0,np.nan).otherwise(raw_data.BMI))\n",
    "raw_data=raw_data.withColumn(\"Insulin\",F.when(raw_data.Insulin==0,np.nan).otherwise(raw_data.Insulin))\n",
    "raw_data.select(\"Insulin\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"BMI\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+------------------+-----------------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|     SkinThickness|          Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+------------------+-----------------+----+------------------------+---+-------+\n",
      "|          6|  148.0|         72.0|              35.0|155.5482233502538|33.6|                   0.627| 50|      1|\n",
      "|          1|   85.0|         66.0|              29.0|155.5482233502538|26.6|                   0.351| 31|      0|\n",
      "|          8|  183.0|         64.0|29.153419593345657|155.5482233502538|23.3|                   0.672| 32|      1|\n",
      "|          1|   89.0|         66.0|              23.0|             94.0|28.1|                   0.167| 21|      0|\n",
      "|          0|  137.0|         40.0|              35.0|            168.0|43.1|                   2.288| 33|      1|\n",
      "+-----------+-------+-------------+------------------+-----------------+----+------------------------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filling nan with mean\n",
    "from pyspark.ml.feature import Imputer\n",
    "imputer=Imputer(inputCols=[\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"BMI\",\"Insulin\"],\n",
    "                outputCols=[\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"BMI\",\"Insulin\"])\n",
    "model=imputer.fit(raw_data)\n",
    "raw_data=model.transform(raw_data)\n",
    "raw_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[6.0,148.0,72.0,3...|\n",
      "|[1.0,85.0,66.0,29...|\n",
      "|[8.0,183.0,64.0,2...|\n",
      "|[1.0,89.0,66.0,23...|\n",
      "|[0.0,137.0,40.0,3...|\n",
      "|[5.0,116.0,74.0,2...|\n",
      "|[3.0,78.0,50.0,32...|\n",
      "|[10.0,115.0,72.40...|\n",
      "|[2.0,197.0,70.0,4...|\n",
      "|[8.0,125.0,96.0,2...|\n",
      "|[4.0,110.0,92.0,2...|\n",
      "|[10.0,168.0,74.0,...|\n",
      "|[10.0,139.0,80.0,...|\n",
      "|[1.0,189.0,60.0,2...|\n",
      "|[5.0,166.0,72.0,1...|\n",
      "|[7.0,100.0,72.405...|\n",
      "|[0.0,118.0,84.0,4...|\n",
      "|[7.0,107.0,74.0,2...|\n",
      "|[1.0,103.0,30.0,3...|\n",
      "|[1.0,115.0,70.0,3...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# applying vector assembler\n",
    "cols=raw_data.columns\n",
    "cols.remove(\"Outcome\")\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['Pregnancies','Glucose','BloodPressure',\n",
    "                                       'SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age'],\n",
    "                            outputCol=\"features\")\n",
    "raw_data=assembler.transform(raw_data)\n",
    "raw_data.select(\"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|     Scaled_features|\n",
      "+--------------------+--------------------+\n",
      "|[6.0,148.0,72.0,3...|[1.78063837321943...|\n",
      "|[1.0,85.0,66.0,29...|[0.29677306220323...|\n",
      "|[8.0,183.0,64.0,2...|[2.37418449762590...|\n",
      "|[1.0,89.0,66.0,23...|[0.29677306220323...|\n",
      "|[0.0,137.0,40.0,3...|[0.0,4.5012560836...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# applying standard scaler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "standardscaler=StandardScaler().setInputCol(\"features\").setOutputCol(\"Scaled_features\")\n",
    "raw_data=standardscaler.fit(raw_data).transform(raw_data)\n",
    "raw_data.select(\"features\",\"Scaled_features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Scaled_features                                                                                                                                       |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.7806383732194306,4.862670805688543,5.952210601826984,3.9813708583353558,1.8295247783934943,4.887165154544966,1.8923811872495484,4.251616970894646] |\n",
      "|[0.29677306220323846,2.7927501248886903,5.456193051674735,3.29885013976358,1.8295247783934943,3.869005747348098,1.0593712866420917,2.6360025219546803]|\n",
      "|[2.3741844976259077,6.0126267394662385,5.290853868290652,3.316302148279125,1.8295247783934943,3.3890163125267176,2.0281980188703295,2.721034861372573]|\n",
      "|[0.29677306220323846,2.9241736601775696,5.456193051674735,2.616329421191805,1.1056078010080843,4.087182763175998,0.5040313529037872,1.785679127775751]|\n",
      "|[0.0,4.501256083644124,3.3067836676816578,3.9813708583353558,1.975979899674023,6.268952921455001,6.905531349963264,2.806067200790466]                 |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.select(\"Scaled_features\").show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "train, test = raw_data.randomSplit([0.75, 0.25], seed=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of ones are 214\n",
      "Percentage of ones are 36.02693602693603\n"
     ]
    }
   ],
   "source": [
    "# checking imbalance in training set\n",
    "dataset_size=float(train.select(\"Outcome\").count())\n",
    "numPositives=train.select(\"Outcome\").where('Outcome == 1').count()\n",
    "per_ones=(float(numPositives)/float(dataset_size))*100\n",
    "numNegatives=float(dataset_size-numPositives)\n",
    "print('The number of ones are {}'.format(numPositives))\n",
    "print('Percentage of ones are {}'.format(per_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancingRatio = 0.6397306397306397\n"
     ]
    }
   ],
   "source": [
    "# calculating balance ratio\n",
    "BalancingRatio= numNegatives/dataset_size\n",
    "print('BalancingRatio = {}'.format(BalancingRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      classWeights|\n",
      "+------------------+\n",
      "|0.3602693602693603|\n",
      "|0.3602693602693603|\n",
      "|0.3602693602693603|\n",
      "|0.3602693602693603|\n",
      "|0.3602693602693603|\n",
      "+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adding classWeights column in train set\n",
    "train=train.withColumn(\"classWeights\", F.when(train.Outcome == 1,BalancingRatio).otherwise(1-BalancingRatio))\n",
    "train.select(\"classWeights\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Aspect                                                                                                                                   |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[0.0,1.8727853778665335,4.960175501522486,3.316302148279125,1.8295247783934943,3.1562941623102905,2.2183415831394226,5.697166740998825]  |\n",
      "|[0.0,2.4313354028442715,4.2988187679861545,1.1375345309529588,0.42342426421586205,4.043547360010418,0.8118828379108909,1.870711467193644]|\n",
      "|[0.0,2.7598942410664704,5.290853868290652,2.5025759680965094,0.7762778177290804,5.207158111092553,1.6448927385183476,1.785679127775751]  |\n",
      "|[0.0,3.2855883822219885,7.274924068899646,6.825207185717752,1.2937963628818008,6.8071228938304875,2.903462044870918,2.6360025219546803]  |\n",
      "|[0.0,3.3184442660442084,5.12551468490657,3.316302148279125,1.8295247783934943,3.1853844310873436,1.0140990094351647,2.125808485447323]   |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using chisquareSelector\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "css = ChiSqSelector(featuresCol='Scaled_features',outputCol='Aspect',labelCol='Outcome',fpr=0.05)\n",
    "train=css.fit(train).transform(train)\n",
    "test=css.fit(test).transform(test)\n",
    "test.select(\"Aspect\").show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Outcome|prediction|\n",
      "+-------+----------+\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       0.0|\n",
      "|      0|       1.0|\n",
      "|      1|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fitting the logistic regression model\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol=\"Outcome\", featuresCol=\"Aspect\",weightCol=\"classWeights\",maxIter=10)\n",
    "model=lr.fit(train)\n",
    "predict_train=model.transform(train)\n",
    "predict_test=model.transform(test)\n",
    "predict_test.select(\"Outcome\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+------------------+-----------------+----+------------------------+---+-------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Pregnancies|Glucose|BloodPressure|     SkinThickness|          Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|            features|     Scaled_features|              Aspect|       rawPrediction|         probability|prediction|\n",
      "+-----------+-------+-------------+------------------+-----------------+----+------------------------+---+-------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|          0|   57.0|         60.0|29.153419593345657|155.5482233502538|21.7|                   0.735| 67|      0|[0.0,57.0,60.0,29...|[0.0,1.8727853778...|[0.0,1.8727853778...|[3.84066523834802...|[0.97897235159879...|       0.0|\n",
      "+-----------+-------+-------------+------------------+-----------------+----+------------------------+---+-------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+--------------------+\n",
      "|Outcome|       rawPrediction|prediction|         probability|\n",
      "+-------+--------------------+----------+--------------------+\n",
      "|      0|[3.84066523834802...|       0.0|[0.97897235159879...|\n",
      "|      0|[2.86492478535243...|       0.0|[0.94608505614275...|\n",
      "|      0|[1.69781957503435...|       0.0|[0.84524974428250...|\n",
      "|      0|[-0.1056353100376...|       1.0|[0.47361570272801...|\n",
      "|      0|[2.70237566566379...|       0.0|[0.93716668108294...|\n",
      "+-------+--------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "The area under ROC for train set is 0.8270167240531232\n",
      "The area under ROC for test set is 0.8746913580246912\n"
     ]
    }
   ],
   "source": [
    "# evaluating\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol=\"Outcome\")\n",
    "predict_test.select(\"Outcome\",\"rawPrediction\",\"prediction\",\"probability\").show(5)\n",
    "print(\"The area under ROC for train set is {}\".format(evaluator.evaluate(predict_train)))\n",
    "print(\"The area under ROC for test set is {}\".format(evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning and K fold cross validation\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.aggregationDepth,[2,5,10])\\\n",
    "    .addGrid(lr.elasticNetParam,[0.0, 0.5, 1.0])\\\n",
    "    .addGrid(lr.fitIntercept,[False, True])\\\n",
    "    .addGrid(lr.maxIter,[10, 100, 1000])\\\n",
    "    .addGrid(lr.regParam,[0.01, 0.5, 2.0]) \\\n",
    "    .build()\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "cvModel = cv.fit(train)\n",
    "predict_train=cvModel.transform(train)\n",
    "predict_test=cvModel.transform(test)\n",
    "print(\"The area under ROC for train set after CV  is {}\".format(evaluator.evaluate(predict_train)))\n",
    "print(\"The area under ROC for test set after CV  is {}\".format(evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
