{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating spark context object\n",
    "conf = SparkConf().setAppName(\"Pyspark Pgm\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading file\n",
    "contentRDD =sc.textFile(\"simple_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(contentRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing non empty lines\n",
    "nonempty_lines = contentRDD.filter(lambda x: len(x) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nonempty_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into words\n",
    "words = nonempty_lines.flatMap(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apache',\n",
       " 'Spark',\n",
       " 'is',\n",
       " 'an',\n",
       " 'open-source',\n",
       " 'distributed',\n",
       " 'general-purpose',\n",
       " 'cluster-computing',\n",
       " 'framework.',\n",
       " '',\n",
       " 'Spark',\n",
       " 'provides',\n",
       " 'an',\n",
       " 'interface',\n",
       " 'for',\n",
       " 'programming',\n",
       " 'entire',\n",
       " 'clusters',\n",
       " 'with',\n",
       " 'implicit',\n",
       " 'data',\n",
       " 'parallelism',\n",
       " 'and',\n",
       " 'fault',\n",
       " 'tolerance.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing empty strings\n",
    "words = words.filter(lambda x:len(x)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apache',\n",
       " 'Spark',\n",
       " 'is',\n",
       " 'an',\n",
       " 'open-source',\n",
       " 'distributed',\n",
       " 'general-purpose',\n",
       " 'cluster-computing',\n",
       " 'framework.',\n",
       " 'Spark',\n",
       " 'provides',\n",
       " 'an',\n",
       " 'interface',\n",
       " 'for',\n",
       " 'programming',\n",
       " 'entire',\n",
       " 'clusters',\n",
       " 'with',\n",
       " 'implicit',\n",
       " 'data',\n",
       " 'parallelism',\n",
       " 'and',\n",
       " 'fault',\n",
       " 'tolerance.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting words\n",
    "wordcount = words.map(lambda x:(x,1)).reduceByKey(lambda x,y: x+y).map(lambda x: (x[1], x[0])).sortByKey(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Spark\n",
      "2 an\n",
      "1 Apache\n",
      "1 is\n",
      "1 open-source\n",
      "1 general-purpose\n",
      "1 cluster-computing\n",
      "1 provides\n",
      "1 programming\n",
      "1 entire\n",
      "1 clusters\n",
      "1 implicit\n",
      "1 fault\n",
      "1 distributed\n",
      "1 framework.\n",
      "1 interface\n",
      "1 for\n",
      "1 with\n",
      "1 data\n",
      "1 parallelism\n",
      "1 and\n",
      "1 tolerance.\n"
     ]
    }
   ],
   "source": [
    "# printing words and thier numbers\n",
    "for word,count in wordcount.collect():\n",
    "    print(word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
